{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "third-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.debug.metrics as met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occupied-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['XRT_DEVICE_MAP'] = \"CPU:0;/job:localservice/replica:0/task:0/device:XLA_CPU:0\"\n",
    "os.environ['XRT_WORKERS'] = \"localservice:0;grpc://localhost:40501\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "partial-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_w = torch.rand(1000, 1).to(torch.float64)\n",
    "pred_h = torch.rand(1000, 1)\n",
    "pred_ctr_x = torch.rand(1000, 1)\n",
    "pred_ctr_y = torch.rand(1000, 1)\n",
    "pred_boxes_cpu = torch.rand(1000, 4)\n",
    "pred_boxes_xla = torch.rand(1000, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "increased-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU Golden Results \n",
    "pred_boxes_cpu[:, 0::4] = pred_ctr_x - 0.5 * pred_w\n",
    "# y1\n",
    "pred_boxes_cpu[:, 1::4] = pred_ctr_y - 0.5 * pred_h\n",
    "# x2 (note: \"- 1\" is correct; don't be fooled by the asymmetry)\n",
    "pred_boxes_cpu[:, 2::4] = pred_ctr_x + 0.5 * pred_w - 1\n",
    "# y2 (note: \"- 1\" is correct; don't be fooled by the asymmetry)\n",
    "pred_boxes_cpu[:, 3::4] = pred_ctr_y + 0.5 * pred_h - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "green-romania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xla:0\n"
     ]
    }
   ],
   "source": [
    "dev = xm.xla_device()\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "later-choir",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Internal: From /job:localservice/replica:0/task:0:\n2 root error(s) found.\n  (0) Internal: Seen floating point types of different precisions in %pad.119 = f64[1000,4]{1,0} pad(f32[1000,1]{1,0} %convert.67, f64[] %constant.118), padding=0_0_0x2_1_1, but mixed precision is disallowed.\n\t [[{{node XRTCompile}}]]\n\t [[XRTCompile_G3]]\n  (1) Internal: Seen floating point types of different precisions in %pad.119 = f64[1000,4]{1,0} pad(f32[1000,1]{1,0} %convert.67, f64[] %constant.118), padding=0_0_0x2_1_1, but mixed precision is disallowed.\n\t [[{{node XRTCompile}}]]\n0 successful operations.\n0 derived errors ignored.\nRecent warning and error logs:\n  OP_REQUIRES failed at xrt_compile_ops.cc:220 : Internal: Seen floating point types of different precisions in %pad.119 = f64[1000,4]{1,0} pad(f32[1000,1]{1,0} %convert.67, f64[] %constant.118), padding=0_0_0x2_1_1, but mixed precision is disallowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c833e0ff8825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# y2 (note: \"- 1\" is correct; don't be fooled by the asymmetry)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mpred_boxes_xla\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_ctr_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpred_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mxm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hack1/lib/python3.6/site-packages/torch_xla-1.9-py3.6-linux-x86_64.egg/torch_xla/core/xla_model.py\u001b[0m in \u001b[0;36mmark_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m    716\u001b[0m   torch_xla._XLAC._xla_step_marker(\n\u001b[1;32m    717\u001b[0m       \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_XLAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xla_get_default_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m       wait=xu.getenv_as('XLA_SYNC_WAIT', bool, False))\n\u001b[0m\u001b[1;32m    719\u001b[0m   \u001b[0;31m# Only emit metrics from the first local device index, to avoid emitting the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m   \u001b[0;31m# same values from different threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Internal: From /job:localservice/replica:0/task:0:\n2 root error(s) found.\n  (0) Internal: Seen floating point types of different precisions in %pad.119 = f64[1000,4]{1,0} pad(f32[1000,1]{1,0} %convert.67, f64[] %constant.118), padding=0_0_0x2_1_1, but mixed precision is disallowed.\n\t [[{{node XRTCompile}}]]\n\t [[XRTCompile_G3]]\n  (1) Internal: Seen floating point types of different precisions in %pad.119 = f64[1000,4]{1,0} pad(f32[1000,1]{1,0} %convert.67, f64[] %constant.118), padding=0_0_0x2_1_1, but mixed precision is disallowed.\n\t [[{{node XRTCompile}}]]\n0 successful operations.\n0 derived errors ignored.\nRecent warning and error logs:\n  OP_REQUIRES failed at xrt_compile_ops.cc:220 : Internal: Seen floating point types of different precisions in %pad.119 = f64[1000,4]{1,0} pad(f32[1000,1]{1,0} %convert.67, f64[] %constant.118), padding=0_0_0x2_1_1, but mixed precision is disallowed."
     ]
    }
   ],
   "source": [
    "# Test case:\n",
    "# https://github.com/asuhan/maskrcnn-benchmark/blob/9063850dc3069dce9d6a8ce9f65f8449b1cd3be7/maskrcnn_benchmark/modeling/box_coder.py#L85\n",
    "# I'm not sure why in the code above, the multiply factor 0.5 gets to transfer to FP64 by default. \n",
    "# Here, I did torch.tensor(0.5, dtype = torch.float64, device = dev) to reproduce the error I saw previous: mixed precisions\n",
    "pred_w = pred_w.to(dev)\n",
    "pred_h = pred_h.to(dev)\n",
    "pred_ctr_x = pred_ctr_x.to(dev)\n",
    "pred_ctr_y = pred_ctr_y.to(dev)\n",
    "\n",
    "rel_codes = pred_boxes_cpu.to(dev)\n",
    "pred_boxes_xla = torch.zeros_like(rel_codes)\n",
    "pred_boxes_xla[:, 0::4] = pred_ctr_x - torch.tensor(0.5, dtype = torch.float64, device = dev)  * pred_w\n",
    "# y1\n",
    "pred_boxes_xla[:, 1::4] = pred_ctr_y - torch.tensor(0.5, dtype = torch.float64, device = dev) * pred_h\n",
    "# x2 (note: \"- 1\" is correct; don't be fooled by the asymmetry)\n",
    "pred_boxes_xla[:, 2::4] = pred_ctr_x + torch.tensor(0.5, dtype = torch.float64, device = dev) * pred_w - 1\n",
    "# y2 (note: \"- 1\" is correct; don't be fooled by the asymmetry)\n",
    "pred_boxes_xla[:, 3::4] = pred_ctr_y + torch.tensor(0.5, dtype = torch.float64, device = dev) * pred_h - 1\n",
    "xm.mark_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will see above bug if return FP64 to XLA_GPU/CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unusual-liberty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.1625e-02,  1.2382e-01, -8.2171e-04, -4.5915e-02],\n",
      "        [ 3.3453e-01,  1.9495e-01, -3.9123e-01, -5.0426e-01],\n",
      "        [ 2.8908e-01,  8.7252e-01,  2.3290e-01,  3.2853e-02],\n",
      "        ...,\n",
      "        [-2.9353e-02,  4.6598e-01, -2.8248e-01,  2.5617e-01],\n",
      "        [ 1.6288e-02,  6.0928e-01, -8.6419e-01, -3.0415e-01],\n",
      "        [ 3.6718e-01,  6.8817e-01, -6.5811e-03, -2.0635e-01]], device='xla:0')\n"
     ]
    }
   ],
   "source": [
    "# Won't have issue if return FP32 to XLA_GPU/CPU\n",
    "print(pred_boxes_xla) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "canadian-horizon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.9605e-08, device='xla:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XLA vs CPU results\n",
    "torch.max(torch.abs(pred_boxes_xla - pred_boxes_cpu))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hack1] *",
   "language": "python",
   "name": "conda-env-hack1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
